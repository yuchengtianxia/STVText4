# Temporal Clustering for Spatio-Temporal Video Scene Text Detection

## Abstract
With only bounding-box annotations in the spatial domain, existing video scene text detection (VSTD) benchmarks lack temporal relation of text instances among video frames, which hinders the development of video text-related applications. In this paper, through systematically introducing a new large-scale benchmark, named as STVText4, a well-designed spatial-temporal detection metric (STDM) and a novel clustering-based baseline method, referred to as Temporal Clustering (TC), we open a challenging yet promising direction of VSTD, termed as ST-VSTD, targeting at simultaneously detecting video scene texts in both spatial and temporal domains. STVText4 contains more than 1.4 million text instances from 161,347 video frames of 106 videos, where each instance is annotated with not only spatial bounding box and temporal range but also four intrinsic attributes, including legibility, density, scale, and lifecycle, to significantly facilitate the community. With continuous propagation of identical texts in the video sequence, TC can accurately output the spatial quadrilateral and temporal range of the texts, which sets a strong baseline for ST-VSTD. Extensive experiments demonstrate the superiority of our method and the great academic and practical value of the STVText4. The code is available in the supplementary materials.

### More detailed readme Doc are being sorted out
